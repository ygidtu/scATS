{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c74a8a-77e9-4068-9284-d02a12c5076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pyBigWig\n",
    "import numpy as np\n",
    "\n",
    "from rich import print\n",
    "from pybedtools.bedtool import BedTool\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b34fc-f450-42d2-83e5-024843feb88f",
   "metadata": {},
   "source": [
    "准备sample以及regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8b1ca6a-d401-474e-88f7-762b2f1e84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bed:\n",
    "    def __init__(self, chrom, start, end, name):\n",
    "        self.chrom = chrom\n",
    "        self.start= start\n",
    "        self.end = end\n",
    "        self.name = name\n",
    "        \n",
    "    @property\n",
    "    def center(self):\n",
    "        return (self.end + self.start) // 2\n",
    "\n",
    "\n",
    "def set_name(data, name = 1, size=-1):\n",
    "    data = []\n",
    "    \n",
    "    for i in cage:\n",
    "        data.append(Bed(i.chrom, i.start, i.stop, name))\n",
    "    \n",
    "    if size > 0:\n",
    "        return data[:size]\n",
    "    return data\n",
    "    \n",
    "cage = BedTool(\"/mnt/raid64/ATS/rawdata/CAGE/large%20cell%20lung%20carcinoma%20cell%20line%3aIA-LM.CNhs11277.10509-107D5.hg38.ctss.bed.gz\")\n",
    "x = BedTool()\n",
    "y = x.random(l=1, n=len(cage), genome='hg38', seed=42)\n",
    "\n",
    "y = y.intersect(cage, v=True)\n",
    "\n",
    "sample = set_name(cage, size = 10000) + set_name(y, name = 0, size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5502c65-acb7-4c41-a8b0-9de3e6f7d1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f673fbe6fe445358d206af2a7d6ea99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_values(args):\n",
    "    bw, region, span = args\n",
    "    bw = pyBigWig.open(bw)\n",
    "    \n",
    "    try:\n",
    "        x = bw.values(region.chrom, region.center - span, region.center + span)\n",
    "        return x, region.name\n",
    "    except Exception as err:\n",
    "        return np.zeros(span * 2 + 1), 0\n",
    "    \n",
    "class Dataset:\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, data, bw):\n",
    "        'Initialization'\n",
    "        self.data = data\n",
    "        self.bw = bw\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "    \n",
    "  def getitem(self, n_jobs=10, span:int=1000):\n",
    "        'Generates one sample of data'\n",
    "        \n",
    "        x, y = [], []\n",
    "        with Pool(n_jobs) as p:\n",
    "            res = list(tqdm(p.imap(load_values, [[self.bw, x, span] for x in self.data]), total=len(self.data)))\n",
    "        \n",
    "        for i, j in res:\n",
    "            x.append(i)\n",
    "            y.append(j)\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "training_set = Dataset(sample, \"/mnt/raid64/ATS/rawdata/ENCODE/ATAC/ENCFF059JAV.bigWig\")\n",
    "training_set.getitem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bba1b5d-b991-47fc-9d1d-a29dcc686ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, y_train, y_test = train_test_split(training_set.x, training_set.y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "177a7bfb-6405-49b0-b17f-c330a309a886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.15716666666666668</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accuracy: \u001b[1;36m0.15716666666666668\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred=clf.predict(x_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c481ab3e-e4d0-4899-b2ac-1cee552f28ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m0.5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, training_set.x, training_set.y, cv=5, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bd3e88d-b163-4415-acdf-059c6e46b79e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.grid_search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11760/2242320571.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_search\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Set the parameters by cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m tuned_parameters = [\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.grid_search'"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "    { \n",
    "        'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],    \n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(RandomForestClassifer(), tuned_parameters, cv=5, scoring=score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_estimator_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() / 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7fd14-028a-4347-a6c4-a0b3603b66ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
